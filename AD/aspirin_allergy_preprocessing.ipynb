{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspirin Allergy\n",
    "## Import dataframe which contains usernames and according phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('final_aspirin_allergy_df.csv')\n",
    "raw_names = df[\"name\"].tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change names in column \"name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_user = None\n",
    "\n",
    "processed_names = []\n",
    "\n",
    "sample_string = \"836.23andme.413\"\n",
    "\n",
    "# delete \".23andme\" and replace with \"_file\" and add \"user\" in front\n",
    "def clean_name(filename: str):\n",
    "    garbage = \".23andme.\"\n",
    "    temp_string = filename.replace(garbage,\"_file\")\n",
    "    return \"user\"+temp_string\n",
    "new_names = []\n",
    "for i in raw_names:\n",
    "    new_names.append(clean_name(i))\n",
    "\n",
    "df[\"name\"] = new_names\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access files in directory\n",
    "### all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "directory = \"D:/Leah Data/patientFiles\"\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        print(filename.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### files which end with 23andme.txt and 23andme-exome-vcf.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\"23andme.txt\") or filename.endswith(\"23andme-exome-vcf.txt\"):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23andme.txt files from dataframe, patients aspirin allergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store names of 23andme.txt files in list\n",
    "patient_files_aspirin = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.startswith(tuple(new_names)):\n",
    "        patient_files_aspirin.append(file)\n",
    "\n",
    "print(len(patient_files_aspirin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over files to clear and save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "#check if lines include a Hash\n",
    "def hasHash(line: str):\n",
    "    if \"#\" in line:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#get RSID from textfile\n",
    "def getRSID(line: str):\n",
    "        return line[:line.index(\"\\t\")]\n",
    "\n",
    "#get genotype from textfile\n",
    "def getGenotype(line: str):\n",
    "    if line[-3] == \"\\t\":\n",
    "        return line[-2:-1]\n",
    "    else:\n",
    "        return line[-3:-1]\n",
    "\n",
    "#get position from textfile\n",
    "def getPosition(line: str):\n",
    "    counter = 0\n",
    "    for i, char in enumerate(line):\n",
    "        if char == \"\\t\":\n",
    "            counter = counter + 1\n",
    "\n",
    "        if counter == 2:\n",
    "            x = line[i+1:]\n",
    "            return x[:x.index(\"\\t\")]\n",
    "\n",
    "\n",
    "file_location = 'D:/Leah Data/patientFiles/'\n",
    "\n",
    "successOpen = 0\n",
    "failOpen = 0\n",
    "failOpenArray = []\n",
    "\n",
    "run = False\n",
    "\n",
    "if run:\n",
    "\n",
    "    # iterate through each filename in the list\n",
    "    for i, fileName in enumerate(patient_files_aspirin):\n",
    "        rsid = []\n",
    "        position = []\n",
    "        genotype = []\n",
    "\n",
    "        #### Condition to check if we want to open the file\n",
    "        print(\"Trying to open: \", fileName)\n",
    "        \n",
    "        # OPEN\n",
    "        try:\n",
    "            aspirinfile = open(file_location + fileName)\n",
    "            fileContents = aspirinfile.readlines()\n",
    "            # HERE GOES THE PROCESSING - FILE IS OPENED\n",
    "            for line in fileContents:\n",
    "                if hasHash(line)==False:\n",
    "                    rsid.append(getRSID(line))\n",
    "                    genotype.append(getGenotype(line))\n",
    "                    position.append(getPosition(line))\n",
    "                    \n",
    "            # SAVE FILE WITH THE ACC. DATA\n",
    "            x = {\"rsid\":rsid, \"position\":position, \"genotype\":genotype}\n",
    "            df_aspirin = pd.DataFrame(data = x)\n",
    "            name=\"D:/aspirin_parquets/\"+str(fileName)+\".parquet\"\n",
    "            df_aspirin.to_parquet(name)\n",
    "            # f_name=\"D:/aspirin_parquets/\"+str(fileName)+\".csv\"\n",
    "            # df.to_csv(f_name)\n",
    "            successOpen+=1\n",
    "            aspirinfile.close()\n",
    "            del df_aspirin\n",
    "            print(f\"succesfully stored {fileName[:10]}\")\n",
    "        except:\n",
    "            # print(fileName, \"ERROR. MOVING ON.\")\n",
    "            failOpen+=1\n",
    "            failOpenArray.append(fileName)\n",
    "\n",
    "\n",
    "        #if i == 3:\n",
    "            #break\n",
    "\n",
    "    print(f\"Success opens: {successOpen}\\nFailed opens: {failOpen}\")\n",
    "\n",
    "    print(\"File names of all failed files:\")\n",
    "    print(failOpenArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Tracker to track RSIDs\n",
    "RSID_Tracker = {}\n",
    "\n",
    "#Condition if rsid starts with \"r\"\n",
    "def rsidIsAllowed(rsid: str):\n",
    "\tif  rsid[0]==\"r\":\n",
    "\t\treturn True\n",
    "\telse:\n",
    "\t\treturn False\n",
    "\n",
    "#Condition if genotype has an empty value or is smaller than 2 letters\n",
    "def genotypeIsAllowed(genomeValue: str):\n",
    "\tif genomeValue == \"--\" or len(genomeValue)<2:\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\treturn True\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "read = False\n",
    "\n",
    "clean_file_direction = \"D:/aspirin_parquets/\"\n",
    "\n",
    "\n",
    "if read:\n",
    "\tcommon_rsid_counter = 0\n",
    "\n",
    "\t# Iterate through each parquet file and open\n",
    "\tfor i, filename in enumerate(os.scandir(\"D:/aspirin_parquets\")):\t\t\n",
    "\t\t#if i == 5:\n",
    "\t\t\t#break\n",
    "\n",
    "\t\t# Read parquet file\n",
    "\t\tprint(filename, \"opened! Operating now...\")\n",
    "\t\tpatient = pd.read_parquet(filename)\n",
    "\t\t\n",
    "\t\t# Initiate new column fields for new \"updated\" df\n",
    "\t\tnewRSID = []\n",
    "\t\tnewGenotype=[]\n",
    "\t\tnewPos = []\n",
    "\n",
    "\t\t# 1. get a list from genotype column (or make for loop)\n",
    "\t\tOG_genotype = patient[\"genotype\"].tolist()\n",
    "\t\t\n",
    "\t\t# # 2 get a list from rsid column\n",
    "\t\tOG_RSID = patient[\"rsid\"].tolist()\n",
    "\n",
    "\t\t# # 2.5 get list from positions\n",
    "\t\tOG_pos = patient[\"position\"].tolist()\n",
    "\n",
    "\t\tprint(f\"found {len(OG_genotype)} genotypes\")\n",
    "\n",
    "\t\t# 3. for each value in the list, check if genotype is allowed + for each value in the list, check if ID is allowed\n",
    "\t\tfor j, genome in enumerate(OG_genotype):\n",
    "\n",
    "\t\t\tif genotypeIsAllowed(genome) and rsidIsAllowed(OG_RSID[j]):\n",
    "\t\t\t\tnewGenotype.append(genome)\n",
    "\t\t\t\tnewPos.append(OG_pos[j])\n",
    "\t\t\t\tnewRSID.append(OG_RSID[j])\n",
    "\t\t\t\n",
    "\t\t\t# IN CASE OF ERROR TRACKING UNCOMMENT THE CODE BELOW\n",
    "\t\t\t\n",
    "\t\t\t# elif not rsidIsAllowed(OG_RSID[j]):\n",
    "\t\t\t# \tprint(\"NOT ACCEPTING:\", OG_RSID[j],\". SKIPPING\", OG_RSID[j])\n",
    "\t\t\t# elif not genotypeIsAllowed(genome):\n",
    "\t\t\t# \tprint(\"NOT ACCEPTING:\", genome,\". SKIPPING\",OG_RSID[j])\n",
    "\n",
    "\t\t# STORE THE RESULTS AS CLEANED PARQUET FILES\n",
    "\t\tnew_data = {\"rsid\":newRSID, \"position\": newPos, \"genotype\": newGenotype }\n",
    "\t\tdf_new_patient = pd.DataFrame(data = new_data)\n",
    "\n",
    "\t\tdf_new_patient.to_parquet(clean_file_direction + filename.name )\n",
    "\t\tprint(\"Stored!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count all RSIDs and unique RSIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRSIDS_aspirin = []\n",
    "# allUniqueRSIDS = []\n",
    "\n",
    "clean_file_direction = \"D:/aspirin_parquets/\"\n",
    "read = False \n",
    "\n",
    "if read:\n",
    "\n",
    "    # Iterate through parquet files\n",
    "    for i, filename in enumerate(os.scandir(clean_file_direction)):\n",
    "        print(filename , 'OPEN')\n",
    "        file = pd.read_parquet(filename)\n",
    "\n",
    "        # add every single rsid to list\n",
    "        patientRSIDS = file[\"rsid\"].tolist()\n",
    "    \n",
    "        for j, snp in enumerate(patientRSIDS):\n",
    "            allRSIDS_aspirin.append(snp)\n",
    "        \n",
    "        # if snp not in allUniqueRSIDS:\n",
    "        #     allUniqueRSIDS.append(snp)\n",
    "\n",
    "        # allRSIDS_aspirin.append(patientRSIDS)\n",
    "        print(\"Done. Next:\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(len(allRSIDS_aspirin))\n",
    "    except:\n",
    "        print(\"Couldn't print LEN for some reason\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .csv file with all listed RSIDS \n",
    "\n",
    "import pandas as pd \n",
    "#r = pd.DataFrame({\"all_rsids\":allRSIDS_aspirin})\n",
    "#r\n",
    "\n",
    "#r.to_csv(\"ALL_RSIDS_aspirin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List rsids in patients and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSID_Tracker = {}\n",
    "\n",
    "frame = pd.read_csv(\"ALL_RSIDS_aspirin.csv\")\n",
    "\n",
    "print(\"Opening done.\")\n",
    "print(\"Counting now.\")\n",
    "\n",
    "read = False\n",
    "if read:\n",
    "\n",
    "    # Iterate through each RSID in list and count how often they occure\n",
    "    for i, rsid in enumerate(frame[\"all_rsids\"].tolist()):\n",
    "    \n",
    "    \n",
    "        if rsid in RSID_Tracker:\n",
    "            RSID_Tracker[rsid]+=1\n",
    "        else:\n",
    "            RSID_Tracker[rsid] = 1\n",
    "\n",
    "    import json\n",
    "\n",
    "    # Save results as jason file\n",
    "    print(\"Done. Attempting to save as JSON...\")\n",
    "    with open('counted_RSIDS_aspirin.json', 'w') as fp:\n",
    "        json.dump(RSID_Tracker, fp)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rsids which occure at least in 97% of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Calculation of in how many patients a rsid needs to occure to show a minimun occurence og 97% \n",
    "n_minimum_occurence = int((269/100)* 97)+1\n",
    "print(n_minimum_occurence)\n",
    "\n",
    "# Open file\n",
    "print(\"Opening JSON FILE\")\n",
    "\n",
    "f = open(\"counted_RSIDS_aspirin.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "# Create list with common rsids\n",
    "most_common_rsids_aspirin_patients = []\n",
    "\n",
    "for i, key in enumerate(data):\n",
    "    # print(i)\n",
    "    if data[key] >= n_minimum_occurence:\n",
    "\n",
    "        if key not in most_common_rsids_aspirin_patients:\n",
    "            most_common_rsids_aspirin_patients.append(key)\n",
    "\n",
    "f.close()\n",
    "print(len(most_common_rsids_aspirin_patients))\n",
    "\n",
    "store = False\n",
    "\n",
    "# Create .csv file to store thr most common rsids\n",
    "if store:\n",
    "    print(\"Done. Attempting to store....\")\n",
    "    common_rsids = pd.DataFrame({\"common_rsids\":most_common_rsids_aspirin_patients})\n",
    "    common_rsids.to_csv(\"common_rsids_aspirin.csv\", index=False)\n",
    "    print(\"Done storing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get username of patients with most common rsids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv(\"common_rsids_aspirin.csv\")\n",
    "\n",
    "# Create a list of common rsids and look at the lenght of the list\n",
    "commons = c[\"common_rsids\"].tolist()\n",
    "len(commons)\n",
    "\n",
    "user_with_common_rsids = []\n",
    "\n",
    "user_names = []\n",
    "\n",
    "run = False\n",
    "\n",
    "if run:\n",
    "\n",
    "# # If 100% of rsid are in there\n",
    "    def isFit(patient_rsid_list: list, necessary: list):\n",
    "        \n",
    "        is_included = 0\n",
    "        \n",
    "        for k, value in enumerate(necessary):\n",
    "            if value in patient_rsid_list:\n",
    "                is_included+=1\n",
    "        \n",
    "        if is_included/len(necessary)>=1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    clean_file_direction = \"D:/aspirin_parquets/\"\n",
    "\n",
    "    for j, filename in enumerate(os.scandir(clean_file_direction)):\n",
    "        \n",
    "        # Open file and read\n",
    "        print(j, filename, 'OPEN')\n",
    "        \n",
    "        file = pd.read_parquet(filename)\n",
    "\n",
    "        if isFit(file[\"rsid\"].tolist(),commons):\n",
    "            print(filename,\"is fit\")\n",
    "            user_names.append(filename.name)\n",
    "        else:\n",
    "            print(filename,\" NOT FIT !!!!!!\")\n",
    "\n",
    "    #print(user_names)\n",
    "\n",
    "    users = pd.DataFrame({\"userID\":user_names})\n",
    "\n",
    "    users.to_csv(\"3k_Aspirin_Users_Cleaned.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get username, rsid and genotype and store it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "def get_genotype_values(patientID: str, target_snps: list):    \n",
    "    Userfile = pd.read_parquet(clean_file_direction + patientID)\n",
    "    print(f\"Opened {user.index(patientID)}/{len(user)}: {patientID}.\")\n",
    "\n",
    "    start_timestamp=time.time()\n",
    "\n",
    "    patient_rsids = Userfile[\"rsid\"].tolist()\n",
    "    patient_genotype_list = Userfile[\"genotype\"].tolist()\n",
    "    new_row_vals = []\n",
    "\n",
    "    for s, gene in enumerate(target_snps):\n",
    "        try:\n",
    "            new_row_vals.append(patient_genotype_list[patient_rsids.index(gene)])\n",
    "        except:\n",
    "            print(f\"ERROR: {gene} couldn't identify val for {patientID}\")\n",
    "            new_row_vals.append(np.nan)\n",
    "        #if s == 3:\n",
    "            #break\n",
    "    end = time.time()\n",
    "\n",
    "    \n",
    "    process_time = str(end-start_timestamp)[:5]\n",
    "    print(f\"This file took {process_time} seconds.\\n\")\n",
    "\n",
    "    return new_row_vals\n",
    "   \n",
    "\n",
    "\n",
    "users = pd.read_csv('3k_Aspirin_Users_Cleaned.csv')\n",
    "c = pd.read_csv(\"common_rsids_aspirin.csv\")\n",
    "user = users[\"userID\"].tolist()\n",
    "GenoTypes = pd.DataFrame({\"userID\": user})\n",
    "\n",
    "clean_file_direction = \"D:/aspirin_parquets/\"\n",
    "print(\"Constructing empty dataframe structure...\")\n",
    "col_vals = c[\"common_rsids\"].tolist()\n",
    "\n",
    "\n",
    "# Update all rows using labda function\n",
    "gen_vals = GenoTypes.apply(lambda row: get_genotype_values(row[\"userID\"],col_vals), axis = 1)\n",
    "print(gen_vals)\n",
    "\n",
    "\n",
    "for i in col_vals:\n",
    "    GenoTypes[i] = gen_vals\n",
    "print(\"Finished construction.\")\n",
    "\n",
    "\n",
    "for i, u in enumerate(user):\n",
    "    new_row = gen_vals[i]\n",
    "    for j, col in enumerate(GenoTypes.columns):\n",
    "        if col == \"userID\":\n",
    "            pass\n",
    "        else:\n",
    "            GenoTypes.at[i, col] = new_row[j-1]\n",
    "\n",
    "GenoTypes.to_csv(\"Aspirin_Allergy_DF.csv\", index=False)\n",
    "print(\"Storing done.\")\n",
    "#print(GenoTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS IS THE FINAL DATAFRAME \n",
    "finished_aspirin_df = pd.read_csv(\"Aspirin_Allergy_DF.csv\")\n",
    "finished_aspirin_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f95b24995c6ef655ffa9d54bd829b00250e14679292be6736d298f940e6170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
