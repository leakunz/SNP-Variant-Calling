{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../phenotypes_202211021922.csv', delimiter=';')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary with name of column as key and count of non dash values as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude first 5 columns\n",
    "ignore_cols = [\"user_id\", \"genotype_filename\", \"date_of_birth\", \"chrom_sex\", \"openhumans_name\"]\n",
    "\n",
    "#create dictionary \n",
    "non_dash_counts = {}\n",
    "\n",
    "#loop through each column \n",
    "for i, col in enumerate(df.columns):\n",
    "    \n",
    "    dash_counter = 0\n",
    "\n",
    "    if col not in ignore_cols:\n",
    "        #loop through each value and add 1 to counter if value is a dash\n",
    "        for j, value in enumerate(df[col].tolist()):\n",
    "            if value == \"-\":\n",
    "                dash_counter+=1\n",
    "        #subtract counter from lenght of dataframe to generate number of non_dash_counts       \n",
    "        non_dash_counts[col] = len(df[col].tolist())-dash_counter\n",
    "\n",
    "non_dash_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum value in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max value from non_dash_counts dictionary\n",
    "max_value = max(non_dash_counts.values())\n",
    "\n",
    "\n",
    "#key to max_value\n",
    "key_max = max(non_dash_counts, key= lambda x: non_dash_counts[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40 columns with the most non dash values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from heapq import nlargest\n",
    "\n",
    "#keys of 40 highest values\n",
    "max_40_values = heapq.nlargest(40, non_dash_counts, key = non_dash_counts.get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of non dash values of five columns, which are used for further analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 out of the 40 keys got picked and values got listed\n",
    "Lactose_intolerance = non_dash_counts.get(\"Lactose intolerance\")\n",
    "print(Lactose_intolerance)\n",
    "\n",
    "Nicotine_dependence = non_dash_counts.get(\"Nicotine dependence\")\n",
    "print(Nicotine_dependence)\n",
    "\n",
    "Blood_type = non_dash_counts.get(\"Blood type\")\n",
    "print(Blood_type)\n",
    "\n",
    "Aspirin_Allergy = non_dash_counts.get(\"Aspirin Allergy\")\n",
    "print(Aspirin_Allergy)\n",
    "\n",
    "Haplogroup = non_dash_counts.get(\"mtDNA Haplogroup (PhyloTree)\")\n",
    "print(Haplogroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lactose intolerance\n",
    "\n",
    "###  I'm lactose tolerant -> 0\n",
    "###  I'm lactose intolerant -> 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to list\n",
    "LI = df[\"Lactose intolerance\"].to_list()\n",
    "\n",
    "#count unique values in LI list\n",
    "print(set(LI))\n",
    "\n",
    "#classification of values for lactose tolerant people\n",
    "lactose_tolerant = [\"Lactose tolerant\", \"lactose-tolerant\", \"False\", \"lactose tolerant\", \"No\"]\n",
    "\n",
    "#classification of values for lactose tolerant, lactose intolerant people and people with no entry\n",
    "for i, entry in enumerate(LI):\n",
    "    \n",
    "    if entry in lactose_tolerant:\n",
    "        print(df[\"genotype_filename\"][i],\"--> I'm lactose tolerant\")\n",
    "\n",
    "    elif entry == \"-\":\n",
    "        print(df[\"genotype_filename\"][i],\"no value\")\n",
    "\n",
    "    else:\n",
    "        print(df[\"genotype_filename\"][i],\"--> I'm lactose intolerant\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store genotype filename in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays to append genotype filename regarding phenotype classification\n",
    "Lactose_Tolerant = []\n",
    "Lactose_no_value = []\n",
    "Lactose_Intolerant = []\n",
    "\n",
    "for i, entry in enumerate(LI):\n",
    "    \n",
    "    if entry in lactose_tolerant:\n",
    "        Lactose_Tolerant.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry == \"-\":\n",
    "        Lactose_no_value.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    else:\n",
    "        Lactose_Intolerant.append(df[\"genotype_filename\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "is_intolerant = []\n",
    "\n",
    "# list all the intolerant ones\n",
    "for i, name in enumerate(Lactose_Intolerant):\n",
    "    names.append(name)\n",
    "    is_intolerant.append(1)\n",
    "\n",
    "# list all the tolerant ones\n",
    "for i, name in enumerate(Lactose_Tolerant):\n",
    "    names.append(name)\n",
    "    is_intolerant.append(0)\n",
    "\n",
    "#create dataframe with binary phenotype classification\n",
    "lactose_dataframe = pd.DataFrame({'name': names, 'is_intolerant': is_intolerant})\n",
    "lactose_dataframe \n",
    "\n",
    "#dataframe to csv\n",
    "#lactose_dataframe.to_csv(\"..\\AD/Lactose_Intolerance.csv\", index=False)\n",
    "\n",
    "#csv with only 23andme names\n",
    "ld = lactose_dataframe[lactose_dataframe['name'].str.contains('.23andme.')]\n",
    "final_lactose_dataframe = ld[ld[\"name\"].str.contains(\"23andme-exome-vcf.\") == False]\n",
    "\n",
    "final_lactose_dataframe.to_csv(\"final_lactose_intolerance_df.csv\", index = False)\n",
    "\n",
    "#csv with only .vcf files\n",
    "ld_vcf = lactose_dataframe[lactose_dataframe['name'].str.contains('23andme-exome-vcf.')]\n",
    "ld_vcf.to_csv(\"vcf_final_lactose_intolerance_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nicotine dependence\n",
    "\n",
    "### I'm not addicted -> 0\n",
    "### I was/am addicted -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to list\n",
    "ND = df[\"Nicotine dependence\"].to_list()\n",
    "\n",
    "#count unique values in ND list\n",
    "print(set(ND))\n",
    "\n",
    "#classification of values for people who don't smoke\n",
    "not_smoking = [\"Non-smoker\", \"Never-non-smoker\", \"Don't smoke\", \"Never-non-smoker \", \"Never - smoker \", \"Never\", \"Have tried cigarettes - current non smoker  no addiction to nicotine\"]\n",
    "\n",
    "#classification of values for people who don't smoke, smoke and people with no entry\n",
    "for i,entry in enumerate (ND):\n",
    "\n",
    "    if entry in not_smoking:\n",
    "        print(df[\"genotype_filename\"][i],\"--> I'm not addicted\")\n",
    "    \n",
    "    elif entry == \"-\" or entry == \"na\":\n",
    "        print(df[\"genotype_filename\"][i],\"no value\")\n",
    "\n",
    "    else:\n",
    "        print(df[\"genotype_filename\"][i],\"--> I was/am addicted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store genotype filename in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays to append genotype filename regarding phenotype classification\n",
    "No_Smoker = []\n",
    "Smoking_no_value = []\n",
    "Smoker = []\n",
    "\n",
    "\n",
    "for i,entry in enumerate (ND):\n",
    "\n",
    "    if entry in not_smoking:\n",
    "        No_Smoker.append(df[\"genotype_filename\"][i])\n",
    "    \n",
    "    elif entry == \"-\" or entry == \"na\":\n",
    "        Smoking_no_value.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    else:\n",
    "        Smoker.append(df[\"genotype_filename\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "is_addicted = []\n",
    "\n",
    "# list all the not addicted ones\n",
    "for i, name in enumerate(No_Smoker):\n",
    "    names.append(name)\n",
    "    is_addicted.append(1)\n",
    "\n",
    "# list all the addicted ones\n",
    "for i, name in enumerate(Smoker):\n",
    "    names.append(name)\n",
    "    is_addicted.append(0)\n",
    "\n",
    "#create dataframe with binary phenotype classification \n",
    "nicotine_dataframe = pd.DataFrame({'name': names, 'is_addicted': is_addicted})\n",
    "nicotine_dataframe\n",
    "\n",
    "#dataframe to csv\n",
    "#nicotine_dataframe.to_csv(\"..\\AD/Nicotine_Dependence.csv\",index=False)\n",
    "\n",
    "nd = nicotine_dataframe[nicotine_dataframe['name'].str.contains('.23andme.')]\n",
    "final_nicotine_dataframe = nd[nd[\"name\"].str.contains(\"23andme-exome-vcf.\") == False]\n",
    "\n",
    "final_nicotine_dataframe.to_csv(\"final_nicotine_dependence_df.csv\", index = False)\n",
    "\n",
    "#csv with only .vcf files\n",
    "nd_vcf = nicotine_dataframe[nicotine_dataframe['name'].str.contains('23andme-exome-vcf.')]\n",
    "nd_vcf.to_csv(\"vcf_final_nicotine_dependence_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood type\n",
    "\n",
    "### A -> 1\n",
    "### B -> 2\n",
    "### O -> 3\n",
    "### AB -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to list\n",
    "BT = df[\"Blood type\"].to_list()\n",
    "\n",
    "#count unique values in ND list\n",
    "print(set(BT))\n",
    "\n",
    "#classification of values for people with Bloodtype A,O,B,AB\n",
    "A = [\"A-\", 'A+ (AO/+-) Non-Secretor', 'A+ (A+/0+) ', 'ABO  Kidd:  AG \\tJk(a+b+)', 'A/o -/-',  'A+', 'A+ Secretor / Saliva Non Secretor!!', 'A+ (ao/+-) non-secretor']\n",
    "O = ['O-', 'O/O +/-', 'o rh negative', 'O+', 'O rh negative', 'O/o +/-']\n",
    "B = ['b+', 'B-', 'B+']\n",
    "AB = ['AB-', 'AB+', 'A2B+', 'Ab-', 'Ab+']\n",
    "\n",
    "for i,entry in enumerate (BT):\n",
    "\n",
    "    if entry in A:\n",
    "        print(df[\"genotype_filename\"][i],\"--> A\")\n",
    "    \n",
    "    elif entry in O:\n",
    "        print(df[\"genotype_filename\"][i],\"--> O\")\n",
    "\n",
    "    elif entry in B:\n",
    "        print(df[\"genotype_filename\"][i],\"--> B\")\n",
    "\n",
    "    elif entry in AB:\n",
    "        print(df[\"genotype_filename\"][i],\"--> AB\")\n",
    "    \n",
    "    else:\n",
    "        print(df[\"genotype_filename\"][i],\"no value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store genotype filename in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays to append genotype filename regarding phenotype classification\n",
    "A_Bloodtype = []\n",
    "O_Bloodtype = []\n",
    "B_Bloodtype = []\n",
    "AB_Bloodtype = []\n",
    "Bloodtype_no_value = []\n",
    "\n",
    "for i,entry in enumerate (BT):\n",
    "\n",
    "    if entry in A:\n",
    "        A_Bloodtype.append(df[\"genotype_filename\"][i])\n",
    "    \n",
    "    elif entry in O:\n",
    "        O_Bloodtype.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry in B:\n",
    "        B_Bloodtype.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry in AB:\n",
    "        AB_Bloodtype.append(df[\"genotype_filename\"][i])\n",
    "    \n",
    "    else:\n",
    "        Bloodtype_no_value.append(df[\"genotype_filename\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "has_Bloodtype = []\n",
    "\n",
    "# list all wih Bloodtype A\n",
    "for i, name in enumerate(A_Bloodtype):\n",
    "    names.append(name)\n",
    "    has_Bloodtype.append(1)\n",
    "\n",
    "# list all with Bloodtype B\n",
    "for i, name in enumerate(B_Bloodtype):\n",
    "    names.append(name)\n",
    "    has_Bloodtype.append(2)\n",
    "    \n",
    "# list all with Bloodtype 0\n",
    "for i, name in enumerate(O_Bloodtype):\n",
    "    names.append(name)\n",
    "    has_Bloodtype.append(3)\n",
    "\n",
    "\n",
    "# list all with Bloodtype AB\n",
    "for i, name in enumerate(AB_Bloodtype):\n",
    "    names.append(name)\n",
    "    has_Bloodtype.append(4)\n",
    "\n",
    "#create dataframe with classification (1-4)\n",
    "Bloodtype_dataframe = pd.DataFrame({'name': names, 'has_Bloodtype': has_Bloodtype})\n",
    "Bloodtype_dataframe\n",
    "\n",
    "#dataframe to csv\n",
    "#Bloodtype_dataframe.to_csv(\"..\\AD/Bloodtype.csv\", index=False)\n",
    "\n",
    "bd = Bloodtype_dataframe[Bloodtype_dataframe['name'].str.contains('.23andme.')]\n",
    "final_bloodtype_dataframe = bd[bd[\"name\"].str.contains(\"23andme-exome-vcf.\") == False]\n",
    "\n",
    "final_bloodtype_dataframe.to_csv(\"final_bloodtype_df.csv\", index = False)\n",
    "\n",
    "#csv with only .vcf files\n",
    "bd_vcf = Bloodtype_dataframe[Bloodtype_dataframe['name'].str.contains('23andme-exome-vcf.')]\n",
    "bd_vcf.to_csv(\"vcf_final_bloodtype_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspirin Allergy\n",
    "\n",
    "### No -> 0\n",
    "### I'm allergic/sensitive/intolerant -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to list\n",
    "AA = df[\"Aspirin Allergy\"].to_list()\n",
    "\n",
    "#count unique values in ND list\n",
    "print(set(AA))\n",
    "\n",
    "#classification of values for people with allergies, with no allergies and people with no entry\n",
    "for i,entry in enumerate (AA):\n",
    "\n",
    "    if entry == \"No\":\n",
    "        print(df[\"genotype_filename\"][i],\"-->\",entry)\n",
    "\n",
    "    elif entry == \"-\" or entry == \"Unknown\":\n",
    "        print(df[\"genotype_filename\"][i],\"no value\")\n",
    "        \n",
    "    else:\n",
    "        print(df[\"genotype_filename\"][i],\"--> I'm allergic/sensitive/intolerant\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store genotype filename in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays to append genotype filename regarding phenotype classification\n",
    "Aspirin_Allergy =[]\n",
    "Aspirin_no_value = []\n",
    "Aspirin_no_Allergy = []\n",
    "\n",
    "\n",
    "for i,entry in enumerate (AA):\n",
    "\n",
    "    if entry == \"No\":\n",
    "        Aspirin_no_Allergy.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry == \"-\" or entry == \"Unknown\":\n",
    "        Aspirin_no_value.append(df[\"genotype_filename\"][i])\n",
    "        \n",
    "    else:\n",
    "        Aspirin_Allergy.append(df[\"genotype_filename\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "is_allergic = []\n",
    "\n",
    "# list all the ones with allergy\n",
    "for i, name in enumerate(Aspirin_Allergy):\n",
    "    names.append(name)\n",
    "    is_allergic.append(1)\n",
    "\n",
    "# list all the ones with no allergy\n",
    "for i, name in enumerate(Aspirin_no_Allergy):\n",
    "    names.append(name)\n",
    "    is_allergic.append(0)\n",
    "\n",
    "#create dataframe with binary classification\n",
    "Aspirin_dataframe = pd.DataFrame({'name': names, 'is_allergic': is_allergic})\n",
    "Aspirin_dataframe\n",
    "\n",
    "#dataframe to csv\n",
    "#Aspirin_dataframe.to_csv(\"..\\AD/Aspirin_Allergy.csv\", index=False)\n",
    "\n",
    "ad = Aspirin_dataframe[Aspirin_dataframe['name'].str.contains('.23andme.')]\n",
    "final_aspirin_dataframe = ad[ad[\"name\"].str.contains(\"23andme-exome-vcf.\") == False]\n",
    "\n",
    "final_aspirin_dataframe.to_csv(\"final_aspirin_allergy_df.csv\", index = False)\n",
    "\n",
    "#csv with only .vcf files\n",
    "ad_vcf = Aspirin_dataframe[Aspirin_dataframe['name'].str.contains('23andme-exome-vcf.')]\n",
    "ad_vcf.to_csv(\"vcf_aspirin_allergy_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haplogroup\n",
    "### Haplo L -> 1\n",
    "### Haplo M -> 2\n",
    "### Haplo N -> 3\n",
    "### Haplo R -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to list\n",
    "mH = df[\"mtDNA Haplogroup (PhyloTree)\"].to_list()\n",
    "\n",
    "#count unique values in ND list\n",
    "print(set(mH))\n",
    "\n",
    "#classification of values for people with Haplogroup L,M,N,R\n",
    "Macro_haplogroup_L = ['L3e2a1b1', 'L1b1a', 'L2a1c', 'L2b1a', 'L0a1a', 'L1b1a10', 'L2a1c1', 'L2b2']\n",
    "Macro_haplogroup_M = ['M33a2', 'C5c1a', 'M1a3a', 'M2a1a', 'D5c', 'M9a1a1a4', 'm7b3a', 'D4', 'C1b12', 'D1e']\n",
    "Macro_haplogroup_N = ['I3a', 'A2', 'I1a1', 'I2a', 'X2b', 'X2b4', 'I2 ', 'X2m', 'X2-G225A', 'S2', 'X2C1', 'i3a1', 'W4A1', 'N1a1a1a', 'X2e2a']\n",
    "\n",
    "for i,entry in enumerate (mH):\n",
    "\n",
    "    if entry == \"-\" or entry == \"I don't know \" or entry == 'You act like we all are geneologist' or entry == 'X, X2, X2c, X2c1, N, L1,2,3,4&6':\n",
    "        print(df[\"genotype_filename\"][i],\"--> no value\")\n",
    "\n",
    "    elif entry in Macro_haplogroup_L:\n",
    "        print(df[\"genotype_filename\"][i],\"--> Macro-haplogroup L\")\n",
    "\n",
    "    elif entry in Macro_haplogroup_M:\n",
    "        print(df[\"genotype_filename\"][i],\"--> Macro-haplogroup M\")\n",
    "\n",
    "    elif entry in Macro_haplogroup_N:\n",
    "        print(df[\"genotype_filename\"][i],\"--> Macro-haplogroup N\")\n",
    "\n",
    "    else:\n",
    "        print(df[\"genotype_filename\"][i],\"--> Macro-haplogroup R\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store genotype filename in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays to append genotype filename regarding phenotype classification\n",
    "Haplo_L= []\n",
    "Haplo_M = []\n",
    "Haplo_N = []\n",
    "Haplo_R = []\n",
    "Haplo_no_value = []\n",
    "\n",
    "for i,entry in enumerate (mH):\n",
    "\n",
    "    if entry == \"-\" or entry == \"I don't know \" or entry == 'You act like we all are geneologist' or entry == 'X, X2, X2c, X2c1, N, L1,2,3,4&6':\n",
    "        Haplo_no_value.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry in Macro_haplogroup_L:\n",
    "        Haplo_L.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry in Macro_haplogroup_M:\n",
    "        Haplo_M.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    elif entry in Macro_haplogroup_N:\n",
    "        Haplo_N.append(df[\"genotype_filename\"][i])\n",
    "\n",
    "    else:\n",
    "        Haplo_R.append(df[\"genotype_filename\"][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "has_Haplogroup = []\n",
    "\n",
    "# list all wih Haplogroup L\n",
    "for i, name in enumerate(Haplo_L):\n",
    "    names.append(name)\n",
    "    has_Haplogroup.append(1)\n",
    "\n",
    "# list all with Haplogroup M\n",
    "for i, name in enumerate(Haplo_M):\n",
    "    names.append(name)\n",
    "    has_Haplogroup.append(2)\n",
    "    \n",
    "# list all with Haplogroup N\n",
    "for i, name in enumerate(Haplo_N):\n",
    "    names.append(name)\n",
    "    has_Haplogroup.append(3)\n",
    "\n",
    "\n",
    "# list all with Haplogroup R\n",
    "for i, name in enumerate(Haplo_R):\n",
    "    names.append(name)\n",
    "    has_Haplogroup.append(4)\n",
    "\n",
    "#create dataframe with classification(1-4)\n",
    "Haplogroup_dataframe = pd.DataFrame({'name': names, 'has_Haplogroup': has_Haplogroup})\n",
    "Haplogroup_dataframe\n",
    "\n",
    "#dataframe to csv\n",
    "#Haplogroup_dataframe.to_csv(\"..\\AD/mtDNA_Haplogroup.csv\", index= False)\n",
    "\n",
    "hd = Haplogroup_dataframe[Haplogroup_dataframe['name'].str.contains('.23andme.')]\n",
    "final_haplogroup_dataframe = hd[hd[\"name\"].str.contains(\"23andme-exome-vcf.\") == False]\n",
    "\n",
    "final_haplogroup_dataframe.to_csv(\"final_mtDNA_Haplogroup_df.csv\", index = False)\n",
    "\n",
    "#csv with only .vcf files\n",
    "hd_vcf = Haplogroup_dataframe[Haplogroup_dataframe['name'].str.contains('23andme-exome-vcf.')]\n",
    "hd_vcf.to_csv(\"vcf_final_mtDNA_Haplogroup_df.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f95b24995c6ef655ffa9d54bd829b00250e14679292be6736d298f940e6170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
